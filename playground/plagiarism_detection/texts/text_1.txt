В современном мире совещания и собрания, как в очном (оффлайн), так и в дистанционном (онлайн) формате, являются неотъемлемой частью практически любой организации, от мелких частных компаний до гигантских корпораций и государств [1][2]. Под формат собраний также попадает часть учебного процесса и высших учебных заведений, в частности, проведение коллоквиумов и защита выпускных квалификационных работ [2]. Эти собрания обладают большой важностью и зачастую подлежат дальнейшей обработке, такой как транскрибирование в текстовый формат и анализ, включая разбор на составные части, выделение ключевых моментов и т. п. [1][2].
Важнейшей частью как защит выпускных работ, так и бизнес-собраний чаще всего является обсуждение и уточнение ключевых моментов в форме вопросов, поэтому главным артефактом анализа собраний чаще всего является протоколирование заданных вопросов (и, опционально ответов на них). 
В современных реалиях протоколирование и выделение вопросов на собраниях чаще всего ведется вручную либо членами собрания, либо отдельно выделенным человеком. Однако, традиционные методы ручного транскрибирования и анализа собраний могут быть трудоемкими, затратными по времени и подверженными ошибкам. В этом контексте, автоматическое протоколирование и анализ собраний, включая выделение вопросов, может предложить эффективное решение для оптимизации процессов обработки собраний и повышения их эффективности.
Одним из потенциальных преимуществ автоматического протоколирования вопросов на собраниях является возможность более детального анализа тем и вопросов, обсуждаемых на собраниях, с использованием алгоритмов обработки текста и статистических методов. Это может помочь выявить наиболее актуальные вопросы, выделить мнения и предложения участников, а также провести более детальный анализ динамики обсуждения вопросов на различных собраниях.
Кроме того, автоматическое протоколирование вопросов на собраниях может помочь упростить процесс документирования и архивирования результатов собраний, что важно для долгосрочного хранения информации, а также для обеспечения прозрачности и отчетности в организациях и образовательных учреждениях.
Следовательно, есть необходимость в сервисе для автоматического протоколирования звонков, собраний, встреч с транскрипцией, статистикой и фиксацией вопросов.
Однако, стоит отметить, что автоматическое протоколирование собраний является технологически сложной задачей, и точность таких систем может быть ограничена различными факторами, такими как качество записи звука, различные акценты и диалекты, фоновый шум и т.д. Поэтому, при использовании автоматического протоколирования следует учитывать возможные ошибки и необходимость проверки и редактирования результатов.

Целью данного исследования является создание решения для автоматического протоколирования аудио собраний, встреч, звонков, с транскрипцией аудио, составлениям статистики (время, количество участников, количество вопросов), фиксацией вопросов.
Для достижения цели были поставлены следующие задачи:
1. Провести анализ существующих решений и технологий для автоматического протоколирования, транскрипции речи по аудио-данным.
2. Разработать методы транскрибирования аудио и определения вопросов в распознанном тексте.
3. Спроектировать и разработать решение для автоматического протоколирования, включающий в себя транскрибирование поданного на вход аудио и определение вопросов.
4. Провести анализ разработанного решения

Объектом исследования является автоматическое протоколирование.
Предметом исследования является транскрипция аудиоданных и последующая обработка транскрибированного текста.
Практическая ценность работы: разработанное решение позволит сотрудникам вузов и компаний сократить количество рутинной работы при протоколировании рабочих совещаний (например, очных защит дипломов студентов и аспирантов).


           1 ОБЗОР ПРЕДМЕТНОЙ ОБЛАСТИ
               1.1 Обзор готовых сервисов для проведений собраний с точки зрения электронного протоколирования
Microsoft Teams [3], Google Meet [4] и Zoom [5] - это популярные платформы для проведения онлайн-совещаний, вебинаров и видеоконференций. Они предлагают разнообразные функциональные возможности, включая функции протоколирования совещаний и транскрипции речи. Однако, у каждого из этих сервисов есть свои особенности и недостатки. Возможности транскрипции каждого сервиса:
Microsoft Teams - это коммуникационная и коллаборативная платформа, разработанная Microsoft, включающая функции видеоконференций, чата, обмена файлами и другие инструменты для командной работы. В Microsoft Teams доступна функция записи совещаний, которая позволяет записывать аудио и видео совещания для последующего просмотра. Также в Microsoft Teams есть функция транскрипции речи, которая автоматически создает текстовую версию аудиозаписи совещания.
Характеристики Microsoft Teams в контексте протоколирования совещаний и транскрипции речи:
1. Функция транскрипции речи в Microsoft Teams доступна только в платных планах, таких как Microsoft 365 и Business Premium, что может ограничить доступность этой функции для некоторых пользователей;
2. Автоматическая транскрипция речи в Microsoft Teams может быть не всегда точной, особенно в случаях, когда запись содержит специфическую терминологию или технические термины;
3. Экспорт в формате .docx, .vtt.
Google Meet - это сервис конференций от Google, входящий в состав пакета офисных приложений G Suite (теперь называется Google Workspace). Google Meet предлагает функцию записи совещаний, которая позволяет записывать аудио и видео совещания и сохранять их на Google Диске для последующего просмотра.
Возможности Google Meet в контексте электронного протоколирования:
1. Возможность создавать расшифровки сейчас доступна пользователям Google Meet на компьютере или ноутбуке;
2. Расшифровки встреч на языках, отличных от английского, будут неточными;
3. Расшифровки встреч по умолчанию включены для всех версий Workspace, кроме Google Workspace for Education с лицензией учащегося;
4. Экспорт в google-документ (совместимый с .doсx).
Zoom - это платформа для видеоконференций, предлагающая широкий спектр функций для организации онлайн-совещаний и вебинаров. В Zoom доступна функция записи совещаний, позволяющая записывать аудио и видео совещания, а также сохранять записи на локальном компьютере или в облачном хранилище Zoom для последующего просмотра.
Особенности Zoom в контексте протоколирования совещаний и транскрипции речи:
1. Встроенная функция автоматической транскрипции речи в Zoom доступна только в платных планах, таких как Zoom Business и Zoom Enterprise, что может ограничить доступность этой функции для некоторых пользователей;
2. Автоматическая транскрипция речи в Zoom может иметь ограниченную точность, особенно в случаях, когда запись содержит шумы, перекрытия голосов или специфическую терминологию;
3. Экспорт в формате .vtt.

               1.2 Анализ готовых сервисов для проведений собраний с точки зрения электронного протоколирования
Рассмотренные готовые сервисы для проведения собраний имеют набор сходных недостатков, которые затрудняют их использование в качестве сервисов для упрощенного протоколирования совещаний и защит:
Ограниченная доступность автоматической транскрипции - Встроенная функция автоматической транскрипции речи в Zoom также доступна только в платных планах, таких как Zoom Business и Zoom Enterprise. Это ограничивает доступность функции для пользователей, которые используют бесплатные версии Zoom или более дешевые планы. Аналогично для Google Meet – функционал транскрипции доступен только для платных пользователей Google Workspace, и для Microsoft Teams – функция доступна только в платных планах, таких как Microsoft 365 и Business Premium;
Полное отсутствие поддержки русского языка (Google Meet), либо частичная поддержка (Microsoft Teams, Zoom). Вдобавок к этому закрытость реализации сервисов не дает возможности заранее оценить точность транскрипции, особенно в сложных условиях записи;
Отсутствие инструментов для подсчета статистики полученной транскрипции (кол-во сказанных слов, знаков, вопросов, и т. п.);
Экспорт в форматах (.docx, .vtt), неудобных для обработки программными средствами.

В контексте данных недостатков разработка реализация нового сервиса для автоматического протоколирования, который мог бы учесть такие недостатки рассмотренных сервисов, как поддержку русского языка и сбор и хранения статистики проведенных собраний.

               1.3 Обзор технологий для распознавания и транскрипции речи по аудиоданным
Ключевыми компонентами разрабатываемого решения являются модули для распознавания и транскрипции речи и обработки текса для подсчета статистики и выделения вопросов. Создание решения для транскрипции речи с нуля может быть сложным и трудоемким процессом. Распознавание речи является сложной задачей, требующей экспертных знаний в области обработки сигналов, машинного обучения и языковых моделей. 
Однако, уже существует множество решений для транскрипции речи. Эти решения уже имеют готовые модели и алгоритмы для распознавания речи, а также интеграцию с другими сервисами и инструментами. Они обладают высоким уровнем точности и производительности благодаря обширному опыту и инвестициям в исследования и разработки.
Выбор готового решения для транскрипции речи имеет несколько преимуществ:
1. Быстрота внедрения: Готовые решения уже имеют готовые модели и API, что позволяет быстро интегрировать их в сервис электронного протоколирования без необходимости разработки всего с нуля.
2. Точность и производительность: Готовые решения обычно имеют высокий уровень точности распознавания речи благодаря использованию продвинутых алгоритмов и моделей машинного обучения, а также оптимизации производительности.
3. Гибкость и масштабируемость: Готовые решения обычно предоставляют гибкие настройки и возможность масштабирования в зависимости от потребностей проекта. Они также могут поддерживать различные языки и акценты.
4. Поддержка и обновления: Готовые решения обычно имеют поддержку со стороны разработчиков и постоянные обновления, что позволяет быть в курсе последних технологических достижений и улучшений в области транскрипции речи.

Исходя из поставленных задач и вышеописанных преимуществ было принято решение провести обзор существующих технологий для применения их к задаче автоматического протоколирования.

               1.3.1 Vosk
Vosk - это библиотека с открытым исходным кодом, разработанная компанией Alpha Cephei, для распознавания и транскрипции речи [6]. Она предлагает мощные инструменты для обучения и использования глубоких нейронных сетей в задачах распознавания речи, и может быть полезной в контексте электронного протоколирования собраний и совещаний. Основные концепции библиотеки включают в себя:
1. Функциональность: Vosk предоставляет возможности для распознавания и транскрипции речи на нескольких языках. Она поддерживает обработку аудио файлов в форматах WAV, FLAC, и других, и может работать в режиме реального времени для транскрипции речи на лету. Vosk также предлагает возможность работы с моделями для специализированных областей, таких как медицина или техническая терминология, что может быть полезно при протоколировании специализированных собраний.
2. Простота использования: Vosk предоставляет простой API, который может быть интегрирован в различные приложения и сервисы. Она также имеет документацию с примерами кода на различных языках программирования, что облегчает процесс интеграции и использования библиотеки в проектах электронного протоколирования.
3. Гибкость: Vosk предлагает возможность настройки параметров моделей и процесса распознавания, таких как скорость распознавания, качество транскрипции и другие. Это позволяет адаптировать библиотеку под конкретные требования и условия записей собраний и совещаний [7].
4. Поддержка языков: Vosk поддерживает множество языков, включая английский, русский, испанский, китайский и другие. Это делает ее универсальным решением для протоколирования собраний и совещаний на различных языках.
5. Открытый исходный код: Vosk является проектом с открытым исходным кодом, что позволяет разработчикам настраивать и расширять функциональность библиотеки в соответствии с их потребностями.
6. Производительность: Vosk обладает высокой производительностью и может обрабатывать аудио файлы быстро и эффективно. Она также предлагает возможность использования готовых моделей, обученных на больших объемах данных, что может улучшить точность распознавания речи.
7. Масштабируемость: Vosk позволяет использовать распределенные вычисления, что делает ее масштабируемым решением для обработки больших объемов аудио данных, таких как длинные записи собраний и совещаний.
8. Поддержка активного сообщества: Vosk имеет активное сообщество разработчиков и пользователей, которое предоставляет поддержку, обновления и исправления ошибок. Это позволяет быстро реагировать на изменения и улучшать функциональность библиотеки.
9. Готовые интеграции: Vosk также предлагает готовые интеграции с популярными платформами и инструментами, такими как Python, Java, Node.js, Docker, и другими. Это облегчает процесс интеграции библиотеки в существующие проекты и системы электронного протоколирования.
10. Бесплатная лицензия: Vosk доступна на условиях лицензии Apache 2.0, что позволяет использовать ее бесплатно в коммерческих и некоммерческих проектах, без ограничений на количество использования и доступа к исходному коду.
Можно выделить следующие ключевые характеристики библиотеки Vosk:
1. Распознавание речи в реальном времени (Streaming API): Vosk может обрабатывать аудио-сигналы в реальном времени и распознавать речь на ходу [6].
2. Высокая точность распознавания: Vosk использует технологию распознавания речи на основе нейронных сетей, что позволяет достигать высокой точности распознавания речи. Также имеется возможность до-обучения моделей на своем наборе данных [7].
3. Поддержка 20+ языков: Vosk поддерживает распознавание речи на нескольких языках, включая английский, испанский, русский, китайский и другие [6].
4. Функциональность для выделения голосовых профилей спикеров [6].
5. Простота использования: Vosk имеет простой и понятный интерфейс программирования приложений (API), что облегчает интеграцию с другими приложениями.
6. Решение поддерживает работу без доступа к интернете при загрузке модели на устройство

               1.3.2 Whisper
Whisper - открытая система автоматического распознавания речи (ASR), разработанная компанией OpenAI, и обучена на огромном наборе данных, состоящем из 680 000 часов многоязычных и многозадачных контролируемых данных, собранных из Интернета [8]. Это делает Whisper мощным инструментом для обработки и транскрипции речевых данных на различных языках и с разными акцентами.
Whisper является универсальной моделью распознавания речи, способной выполнять многоязычное распознавание речи, перевод речи и идентификацию языка. Благодаря обширному обучению на многоязычных данных, Whisper может работать с различными языками и адаптироваться к разным голосам и стилям речи.
Одной из ключевых особенностей Whisper является его масштабируемость и гибкость. Модель может быть интегрирована в различные приложения и сервисы, такие как электронное протоколирование, автоматическая транскрипция звонков, создание субтитров и другие. Whisper API предоставляет разработчикам удобный интерфейс для интеграции модели в их приложения и платформы [7].
Архитектура Whisper представляет собой сквозной подход, реализованный в виде преобразователя кодер-декодер [9]. Входной звук разбивается на 30-секундные фрагменты, преобразуется в спектрограмму log-Mel [9], а затем передается в кодировщик. Декодер обучен предсказывать соответствующий текстовый заголовок, смешанный со специальными токенами, которые направляют единую модель для выполнения таких задач, как идентификация языка, временные метки на уровне фраз, транскрипция многоязычной речи и перевод речи на английский язык.
Из особенностей можно выделить ориентированность на транскрипцию целых аудиозаписей (отсутствует Streaming API), что позволяет лучше проанализировать запись и получить большую точность транскрипции по сравнения с потоковыми решениями [9]. Также решение не предоставляет функционал для распознавания спикеров или разделения транскрипции по звуковым дорожкам. Решение поддерживает работу без доступа к интернете при загрузке модели на устройство.

               1.3.3 Google Cloud Speech API
Google Cloud Speech API - это платный сервис автоматического распознавания речи от Google Cloud, которая предоставляет возможность транскрипции аудио- и видеофайлов в текст [10]. Ключевые особенности Google Cloud Speech API:
1. Широкий спектр поддерживаемых языков: Google Cloud Speech API поддерживает более 120 языков, включая русский, что делает его гибким решением для обработки речи на различных языках.
2. Высокое качество распознавания: Google Cloud Speech API использует передовые технологии машинного обучения, такие как нейронные сети, что обеспечивает высокое качество распознавания речи с малым количеством ошибок. Он также может автоматически адаптироваться к различным акцентам, дикциям и шумам, что особенно важно при обработке аудиофайлов разных качеств в контексте электронного протоколирования.
3. Гибкие варианты аудио-входа: Google Cloud Speech API поддерживает различные варианты аудио-входа, включая загрузку аудиофайлов, передачу потока аудио в реальном времени и интеграцию с Google Cloud Storage. Это позволяет гибко работать с различными источниками аудиоданных, такими как аудиофайлы записей, потоковые аудиоданные в реальном времени и другие форматы, что важно для электронного протоколирования.
4. Различные режимы распознавания: Google Cloud Speech API поддерживает различные режимы распознавания, включая однократное распознавание, потоковое распознавание и длительное распознавание. Это позволяет выбирать наиболее подходящий режим распознавания в зависимости от требований задачи электронного протоколирования.
5. Расширенные функциональности: Google Cloud Speech API также предлагает дополнительные функциональности, такие как определение пауз и временных меток в речи, разделение аудиодорожки на
Поскольку сервис предоставляется в качестве HTTP REST и gRPC API, использование в оффлайн-режиме недоступно или ограниченно.

               1.3.4 Microsoft Azure Speech
Microsoft Azure Speech - это облачный сервис распознавания речи от Microsoft, который предоставляет возможности распознавания и транскрипции речи для ряда различных приложений, включая электронное протоколирование [11]. Некоторые ключевые особенности и возможности Microsoft Azure Speech:
1. Распознавание речи в режиме реального времени: Azure Speech предоставляет возможность распознавания речи в режиме реального времени, что делает его подходящим для приложений, требующих мгновенной транскрипции речи, таких как электронное протоколирование во время совещаний, конференций и презентаций.
2. Многоязычная поддержка: Azure Speech поддерживает распознавание речи на нескольких языках, включая английский, русский, ыиспанский, французский, немецкий, китайский, японский и многие другие, что делает его подходящим для международных проектов и приложений с многоязычным контентом.
3. Адаптивная акустическая модель: Azure Speech использует адаптивные акустические модели, которые могут быть обучены на специфическом аудио-контенте, что делает их более точными и эффективными для специфических приложений электронного протоколирования с учетом особенностей речи и произношения спикеров.
4. Обработка аудио-контента различных форматов: Azure Speech поддерживает обработку аудио-контента различных форматов, включая WAV, MP3, OGG, FLAC и другие, что делает его гибким решением для работы с различными типами аудио-файлов.
5. Контроль качества распознавания речи: Azure Speech предоставляет возможности контроля и настройки качества распознавания речи, включая настройку параметров, таких как скорость распознавания, уровень шума, и другие, что позволяет достичь оптимального качества транскрипции в зависимости от конкретных требований проекта электронного протоколирования.
Поскольку сервис предоставляется в качестве HTTP REST API, использование в оффлайн-режиме недоступно или ограниченно.
               1.4 Анализ технологий для распознавания и транскрипции речи по аудиоданным для задачи электронного протоколирования
Для сравнения применительно к проблеме электронного протоколирования были выбраны следующие критерии сравнения:
1. Наличие Streaming API, т. е. возможности обработки аудио-потока в реальном времени
2. Наличие временных меток в транскрипции
3. Наличие функционала для разделения и идентификации спикеров
4. Наличие пунктуации в транскрипции (для русского языка)
5. Наличие функционала для созданий статистики по транскрипции (подсчет слов, знаков, метки вопросов)
6. Поддержка распознавания терминов и предметные слов (английские термины в русской речи, сокращения и обозначения)
7. Поддержка работы в оффлайн-режиме (без доступа к интернету)
8. Доступность, т. е. открытость исходного кода и отсутствие в необходимости оплаты
Сравнение аналогов по выбранным критериям приведено в таблице 1.
Таблица 1 – анализ существующих решений в контексте электронного протоколирования
Решение/
критерий
Streaming API
Идентификация спикеров
Пунктуация (рус. яз.)
Статистика
Распознавание терминов
Оффлайн-режим
Доступность
Vosk
+
+
-
-
-
+
+
Whisper
-
-
+
-
+
+
+
Google Cloud Speech API
+
+
-
-
+
-
-
Microsoft Azure Speech
+
+
-
-
+
-
-

Как можно отметить по таблице, ни одно решение в полной мере не отвечает всем рассматриваемым критериям. Облачные сервисы (Google Cloud Speech API и Microsoft Azure Speech) не являются доступными для использования без платной подписки, не поддерживают работу без интернета, а также не предоставляют пунктуацию для русской транскрипции. Vosk и Whisper имеют преимущества и недостатки в сравнении друг с другом, однако по сравнению с облачными решениями являются более доступными и поддерживают оффлайн-режим. Ни один из аналогов также не предоставляет хоты бы базовой статистики транскрибированного текста.
Таким образом, существующие аналоги не позволяют в полной мере выполнить поставленную цель.
           2 ФОРМИРОВАНИЕ ТРЕБОВАНИЙ К РАЗРАБАТЫВАЕМОМУ РЕШЕНИЮ
               2.1 Задача, решаемая разрабатываемым решением
Исходя из поставленной цели, разрабатываемое решение (сервис) должно решать задачу электронного протоколирования совещаний, т. е. обрабатывать входные аудио-данные и выдавать на выходе транскрипцию (текст) с временными метками, метками спикеров, метками вопросов (для каждой фразы должны быть указаны временные метки начала и конца, а также метка определенного спикера и метки вопроса – является ли фраза вопросом), и метаданные или статистику транскрипции (название транскрипции/собрания, дата и время начала транскрипции, дата и время окончания транскрипции,  распознанные спикеры) в формате, который было бы как относительно удобно читать, так и обрабатывать машинными средствами.

               2.2 Формирование требований
Исходя из поставленной задачи можно выделить два пользовательских сценария исходя из характера работы решения: в реальном времени по аудиопотоку (синхронно, онлайн) или же по аудиозаписи (асинхронно, оффлайн).
Пользовательский сценарий синхронной обработки выглядит следующим образом:
1. (Опционально) предварительная запись голосовых данных спикеров в некое хранилище для последующего различения спикеров.
2. При старте собраний подача пользователем аудиопотока собрания (например, от микрофона) на вход решению через пользовательский интерфейс либо интерфейс командной строки.
3. Решение обрабатывает поданный аудиопоток по частям в реальном времени (транскрибирует по фразе за раз, соединяя куски фраз по необходимости в единое целое, ассоциирует каждую фразу с конкретным спикером), до момента остановки пользователем
4. После остановки транскрипции пользователем решение обрабатывает полученную на текущий момент транскрипцию, составляет статистику исходя из поставленной задачи и сохраняет статистику и транскрипцию в некое постоянное хранилище (база данных, файл на диске)
5. Сохраненные транскрипция и статистика доступны для экспорта и чтения как машинными средствами, так и человеком для последующего использования и пост-обработки по надобности.
Пользовательский сценарий асинхронной обработки выглядит следующим образом:
1. (Опционально) предварительная запись голосовых данных спикеров в некое хранилище для последующего различения спикеров.
2. Подача пользователем аудиозаписи собрания в определенном формате (.wav, .m4a, .mp3) на вход решению через пользовательский интерфейс либо интерфейс командной строки.
3. Решение обрабатывает поданную аудиозапись целиком и создает целиковую выходную транскрипцию.
4. После обработки аудиозаписи решение обрабатывает полученную транскрипцию, составляет статистику исходя из поставленной задачи и сохраняет статистику и транскрипцию в некое постоянное хранилище (база данных, файл на диске).
5. Сохраненные транскрипция и статистика доступны для экспорта и чтения как машинными средствами, так и человеком для последующего использования и пост-обработки по надобности.

Исходя из цели работы, анализа аналогов и проработанных пользовательских сценариев были выделены следующие функциональные требования к разрабатываемому решению:
1. Интерфейс для взаимодействия с пользователем, позволяющий начать сессию протоколирования и опциональное предварительное составление голосовых профилей спикеров;
2. Поддержка аудио-форматов .wav, .mp3, .m4a для входных аудиоданных, как наиболее распространённых и удобных для использования аудио-форматов. Поддержка данных аудио-форматов также позволит обрабатывать экспортируемые записи из широко используемых сервиса для проведения звонков и собраний (Google Meet, Microsoft Teams, Zoom, Sber Jazz);
3. Поддержка синхронной и асинхронной обработки (в реальном времени по аудиопотоку; по записи);
4. Результатом обработки должна быть транскрипция, включающая в себя – временные метки, метки вопросов, метки спикеров, и статистика транскрипции, включающая в себя название сессии протоколирования, дату начала сессии протоколирования, дату окончания сессии протоколирования, информацию о распознанных спикерах;
5. Результаты обработки (транскрипция и статистика) должны быть сохранены в постоянное хранилище, чтобы пользователь мог иметь доступ к результатам (прочитать файл на диске либо экспортировать из решения) в любое время в формате CSV (.csv) или JSON (.json). Данные форматы поддерживаются большим количеством графических приложений, табличная структура СSV удобна для чтения пользователем. JSON формат хорошо поддерживается программными средствами для обработки и аналитики.

               2.3 Выбор метода решения
Исходя из цели работы, анализа аналогов и разработанных функциональных требований было принято решение реализовать веб-приложение для синхронной обработки сессии протоколирования (в реальном времени) с использованием входных аудиоданных с микрофона, и приложение командной строки для асинхронного протоколирования для обработки аудиозаписи собрания после его окончания. Разделение функционала электронного протоколирования на два приложения - веб-приложение для протоколирования собрания в реальном времени по аудиоданным с микрофона и приложение командной строки для протоколирования записи собрания обосновано следующими причинами:
1. Удобство использования: Веб-приложение может предоставлять удобный и интуитивно понятный пользовательский интерфейс, который позволяет пользователям протоколировать собрания в реальном времени с помощью микрофона, без необходимости освоения сложных команд командной строки. Такой подход может быть особенно полезен для пользователей, не знакомых с командной строкой или не имеющих опыта работы с техническими приложениями.
2. Гибкость использования: Приложение командной строки может быть полезным для пользователей, предпочитающих работать с командами и скриптами, и желающих автоматизировать процесс протоколирования записи собрания. Такие пользователи могут иметь определенные требования или особенности, которые могут быть реализованы с использованием командной строки, такие как настройка параметров записи, указание определенного формата или расположения сохраняемых данных и т. д.
3. Поддержка различных платформ: Веб-приложение и приложение командной строки могут быть разработаны для разных платформ, таких как веб-браузеры или операционные системы, и могут быть доступны на разных устройствах. Веб-приложение будет доступно через веб-браузеры на компьютерах, планшетах и мобильных устройствах, в то время как приложение командной строки будет доступно на различных операционных системах, таких как Windows, macOS или Linux.
4. Возможность дополнительных функций: Разделение функционала электронного протоколирования на два приложения может также позволить реализовать дополнительные функции, которые могут быть специфичны для каждого из приложений. Например, в веб-приложении можно реализовать возможность взаимодействия с другими участниками собрания, добавления заметок, создания закладок и т. д., тогда как приложение командной строки может быть оптимизировано для автоматической обработки и анализа аудиоданных с использованием различных алгоритмов или интеграции с другими инструментами командной строки.
3 РАЗРАБОТКА РЕШЕНИЯ ДЛЯ ЭЛЕКТРОННОГО ПРОТОКОЛИРОВАНИЯ
               3.1 Общие положения
Исходя из цели работы, разработанных сценариев и требований, а также выбранного метода решения, можно выделить шаги работы решения для электронного протоколирования, которые наглядно представляются диаграммой последовательности, приведенной на рис. 1.

Рисунок 1 – диаграмма последовательности использования решения для электронного протоколирования
Данная диаграмма описывает функционал приложения на высшем уровне, поэтому применима как к веб-приложению для обработки в реальном времени веб-приложением, так и к приложению командной строки для обработки записи.
Важной особенностью является шаг ресэмплинга (перекодировки) аудиоданных в формат, удобный для обработки и создания транскрипции.

               3.2 Проектирование веб-приложения
Архитектура веб-приложения включает в себя следующие элементы:
1. Клиент - Предоставляет интерфейс для создания банка спикеров и обработки собраний и совещаний в реальном времени. Отвечает за запись аудио-данных с микрофона и отправки на сервер.
2. Сервер - отвечает за создание сессий для записи спикеров и обработки собраний, а также за передачу клиентских аудио-данных серверу для распознавания, сохранение транскрибированных данных в базу данных и передачу их на клиент
3. Сервер распознавания речи - отвечает за транскрибирование аудио данных и выделение голосовых признаков
4. База данных – отвечает за хранение транскрипций сессий и статистики
Разделение единого сервера на основной сервер бизнес-логики и сервер распознавания речи необходимо для поддержки протоколирования в реальном времени – если при отправке голосового отрывка на сервер, сам сервер будет непосредственно заниматься его транскрипцией, он будет некоторое время недоступен для приема новых отрывков, что может привести к их потерей и нарушению целостности транскрипции. При вынесении логики транскрипции в отдельный сервер, коммуницирующий с основным сервером бизнес-логики, основной сервер всегда будет готов к приему новых отрывков, а транскрипция будет сохраняться в базу по мере ее поступления с сервера транскрипции.
Таким образом веб-приложение будет предоставлять пользовательский интерфейс пользователю через браузер и реализовывать механизм протоколирования в реальном времени с использованием входных аудиоданных от микрофона. Поскольку клиентская часть реализуется через браузер, значительно упрощается захват аудиопотока с микрофона и передача его на сервер. 
На основании разработанной архитектуры были построены диаграммы последовательностей, отражающие взаимодействие компонентов архитектуры в сценариях записи спикеров и сессии протоколирования. Данные диаграммы представлены на рис. 2 и рис. 3.

Рисунок 2 -- взаимодействие компонентов архитектуры веб-приложения при записи спикера

Рисунок 3 – взаимодействие компонентов архитектуры веб-приложения в сессии протоколирования
На основании разработанных сценариев использования и диаграммы последовательности были спроектировано, что клиентская будет включать в себя следующие элементы:
1. Главная страница
1.1. Ссылка для перехода на страницу предварительной записи спикеров (получения голосовых профилей спикеров)
1.2. Ссылка для перехода на страницу сессии протоколирования
1.3. Ссылка для перехода на страницу экспорта законченных сессий протоколирования
2. Страница предварительной записи спикеров
2.1. Ссылки для возврата на главную страницу, для перехода на другие имеющиеся страницы
2.2. Поле ввода для метки - имени записываемого спикера
2.3. Кнопка для отправки введенного имени спикера, индикатор статуса установки имени спикера
2.4. Кнопка для старта записи спикера
2.5. Кнопка для остановки записи спикера
2.6. Поле с информацией о качестве записи после окончания записи
3. Страница сессии протоколирования
3.1. Ссылки для возврата на главную страницу, для перехода на другие имеющиеся страницы
3.2. Поле ввода для названия сессии, по которому можно будет в дальнейшем определить сессию для экспорта
3.3. Поле выбора пред-записанных голосовых профилей спикеров для распознавания
3.4. Кнопка установки названия сессии и выбранных голосовых профилей
3.5. Кнопка начала протоколирования
3.6. Кнопка остановки протоколирования
3.7. Сообщение о длительности сессии после ее остановки
4. Страница экспорта законченных сессий протоколирования
4.1. Ссылки для возврата на главную страницу, для перехода на другие имеющиеся страницы
4.2. Список законченных сессий протоколирования, включающий в себя название сессии, дату и время начала сессии, дату и время окончания сессии, выбранных и распознанных спикеров
4.3. Кнопку экспорта для каждой сессии в списке сессий
Веб-сервер должен включать в себя следующие элементы:
1. Обработчики для взаимодействия с клиентом и сервером транскрипции
2. Механизм сохранения транскрипции в базу-данных
3. Логику идентификации спикера на основании пред-записанных голосовых профилей и текущего профиля, полученного от сервера транскрипции
4. Логику обработки транскрипции для определения вопросов, анализа и статистики
5. Сервер-распознавания речи должен включать в себя логику для распознавания речи ее транскрипции в поданном аудио-отрывке.
В качестве базы данных необходимо использовать NoSQL-решение, т. к. для решения поставленной задачи нет необходимости хранить сильно связанные и нормализованные данные. Использование NoSQL-решения позволит обеспечить быстрые запись, чтение, быстрый доступ к данным, а также готовые инструменты для манипуляции сохраненными данными для создания статистики.

               3.3 Проектирование приложения командной строки
Приложение командной строки имеет упрощенную архитектуру и будет объединять логику, разделенную в веб-приложении на разные компоненты: содержать пользовательский CLI-интерфейс, логику транскрипции, логику обработки транскрипции и создания статистики, логику сохранения статистики в файл на диск. В качестве хранилища для CLI -приложения был выбран файл на диске, т. е. это упрощает интеграцию приложения с другими приложениями командной строки, и снимает с пользователя необходимость самостоятельно хранить данные для подключения к базе данных.
Интерфейс командной строки должен включать в себя следующие параметры:
1. Параметр для подачи входной аудиозаписи (аудиозаписей)
2. Параметр для подачи пути до модели распознавания речи и транскрипции
3. Опциональный параметр для подачи пред-записанных голосовых профилей спикеров
4. Параметр режима запуска CLI-приложения – протоколирование записи собрания или создание голосовых профилей спикеров

               3.4 Проектирование функционала для распознавания речи и транскрипции аудио данных
На основании проведенного анализа существующих решений можно выделить 2 открытых технологии, на основании которые можно спроектировать функционал распознавания речи и транскрипции – open-source библиотека Vosk, и open-source решение Whisper. Стоит отметить, что поскольку решение Whisper не поддерживает Streaming API, т. е. обработку в реальном времени, его использование ограничивается приложением командной строки, в то время как Vosk можно использовать в веб-приложении, так и в приложении командной строки. 
               3.4.1 Проектирование функционала транскрипции на основе Vosk
Vosk API работает с “сырыми” кусками (отрывками) аудиоданных в формате 16 bit mono PCM, поэтому для корректной работы библиотеки необходимо подготовить входные аудио-данные в независимости от того, подается на вход аудио-стрим или целая запись. Особенностью Vosk является то, что если текущий отрывок является частью фразы, Vosk помечает его как partial result (частичный результат), и использует совместно с дальнейшими поданным отрывками для накопления (accumulation) целой фразы, которая помечается как final result (целый, финальный результат, т.е. целая фраза). Из первичных экспериментов было выяснено, что концом фразы считается длительная пауза (более 1.5 секунд).
В зависимости от настройки входных параметров Vosk API для поданного на вход аудио-отрывка выдает транскрибированные слова с временными метками, и вектор, соответствующий голосовому профилю текущего спикера, вместе с количеством “голосовых кадров” спикера: чем дольше говорил спикер, тем больше кадров прошло с момента начала его реплики. Чем длиннее говорил спикер, тем более точен полученный голосов вектор. 
Для функционала распознавания различных спикеров необходимо уметь хранить и сравнивать голосовые вектора спикеров. Для сравнения векторов была использована метрика cosine distance, для каждого спикера отбирается 5-10 векторов, с наиболее длительной продолжительностью кадров. Для каждого отдельного вектора считается cosine distance с текущим вектором, и берется медианное значение, которое отражает корреляцию текущего вектора с векторами спикера в интервале от 0 до 1, где 0 - максимальное подобие. Для каждого аудио-отрывка полученный голосовой вектор сравнивается с базой спикеров, и выбирается спикер с наибольшим подобием.
Исходя из данных особенностей библиотеки Vosk, был составлен следующий алгоритм транскрибирования на основе Vosk:
1. Получить следующий аудио-отрывок в формате 16 bit mono PCM и подать на вход Vosk
2. Если не был получен final result (было обработана только часть текущая фраза), повторить п. 1, иначе перейти к п. 3.
3. Получить временные метки, транскрибированные слова и данные спикера (голосовой вектор, длительность голосовых кадров) из Vosk-результата
4. Если были успешно получены голосовые данные, сравнить полученный вектор с имеющимися векторами в банке спикеров, выбрать наиболее подходящего спикера
5. Записать обработанную фразу вместе с временными метками и с меткой спикера фразу в итоговый результат
При реализации данного алгоритма в приложении, для веб-приложения данная логика будет реализована на основном сервере, пункты 1–3 должны быть реализованы через взаимодействие с Vosk-сервером транскрипции.
Данный алгоритм можно визуализировать блок-схемой, представленной на рис. 4.
               3.4.2 Проектирование функционала транскрипции на основе Whisper
Решение Whisper, аналогично решению Vosk, также требует ресэмплинга входной аудиозаписи в формат 16 bit mono PCM.
Помимо транскрибированного текста и временных меток, для каждой отрезка с речью решение выдает вероятность того, что данный отрезок не содержит никакой речи (в таком случае выдаются ошибочные текстовые данные). Для отсечения таких отрезков экспериментальным путем был выбран порог в 0.85, т.е. если вероятность того, что отрезок не является речью превышает 85%, отрезок не будет включен в итоговую транскрипцию. Также экспериментально было выяснено, что по умолчанию Whisper пытается распознать спользуемый в речи язык, что при совмещении русской речи и английских терминов получается неудовлетворительно, поэтому необходимо явно указывать русский язык в качестве основного используемого в собрании языка.
Для задачи speech-to-text Whisper предоставляет большой выбор моделей (см. таблица 2), разделенных по качеству распознавания и скорости обработки [12]:
Таблица 2 – доступные модели Whisper
Модель
Кол-во параметров (весов)
Потребление RAM
Относительная скорость
tiny
39 M
~ 1 GB
32x
base
74 M
~ 1 GB
16x
small
244 M
~ 2 GB
6x
medium
769 M
~ 5 GB
2x
large
1550 M
~ 10 GB
1x


 
Рисунок 4 – блок-схема транскрипции с помощью Vosk

Первичные эксперименты показали, что результаты транскрибирования, пригодные для применения в реальных условиях, показывают модели начиная с модели small. 
Сам по себе Whisper не предоставляет функционала для определения спикеров, поэтому было принято решение использовать библиотеку pyannote.audio [13], которая предоставляет решения для различных задач в области аудио обработки, таких как speaker diarization [13], распознавание речи, извлечение признаков и многие другие. Она основана на Python и предоставляет простой и эффективный способ обработки и анализа аудио данных.
Одним из основных решений, предоставляемых pyannote.audio, является speaker diarization - процесс разделения аудиозаписи на сегменты, соответствующие отдельным спикерам. Pyannote.audio предоставляет реализацию state-of-the-art алгоритмов для speaker diarization, включая Deep Embeddings Clustering (DEC), Probabilistic Linear Discriminant Analysis (PLDA) и байесовский гауссовский смесь-модели (GMM) [13]. Она также позволяет использовать комбинацию нескольких алгоритмов для более точного разделения спикеров.
Минусом данного решения является невозможность заранее задать банк спикеров, и осуществить сравнение с ним в процессе обработки, поэтому в данном подходе разметку спикеров (назначение конкретных имен лейблам спикеров) придется осуществлять вручную. Аналогично Whisper, pyannote.audio принимает на целую аудиозапись в формате 16 bit mono PCM, что облегчает использование данного решения совместно с Whisper.
Исходя из данных особенностей библиотеки Whisper, был составлен следующий алгоритм транскрибирования на основе Whisper, с идентификацией спикеров на основе pyannote.audio:
1. ресэмплинг входной аудиозаписи в 16 bit mono PCM формат
2. Подача записи на вход Whisper
3. Подача записи на вход pyannote.audio
4. Наложение текстовых интервалов, полученных из Whisper, с интервалами спикеров, полученных из pyannote.audio, на основании временных меток
5. Запись итогового результата
Пункты 2-3 из-за своей независимости могут быть выполнены в любом порядке, в т.ч. параллельно. Данный алгоритм можно визуализировать блок-схемой, представленной на рис. 5.

Рисунок 5 – алгоритм транскрипции с помощью Whisper и pyannote.audio
Для наложения интервалов был разработан следующий алгоритм (псевдокод):
    for transribed_segment in transcribed_segments:
       for speaker_segment in speaker_segments:
           speaker_interval, speaker_label = speaker_segment
           if is_overlapping(
               (transribed_segment.start, transribed_segment.end),
               (speaker_interval.start, speaker_interval.end),
           ):
               speaker = speaker_label
               break
       else:
           speaker = "UNKNOWN"

       transcribed_result_annotated.append(
           {
               "text": transribed_segment.text,
               "start": transribed_segment.start,
               "end": transribed_segment.end,
               "speaker": speaker,
           }
       )

               3.5 Проектирование функционала для определения вопросов в транскрибированных фразах
               3.5.1 Краткий обзор технологий для распознавания вопросов тексте
Регулярные выражения и rule-based подходы
Использование регулярных выражений и правил на основе грамматики - это классический подход для определения вопросов в тексте. Он основан на задании определенных правил для выделения предложений, которые могут быть вопросами.
Например, одно из таких правил может выглядеть следующим образом: "Если предложение заканчивается знаком вопроса («?»), то это вопрос". Такой подход хорошо работает для простых случаев, но может давать ложноположительные результаты в более сложных случаях, когда знак вопроса может быть использован не только для выражения вопроса, но и для других целей, например, для выражения удивления.
Регулярные выражения также могут использоваться для поиска ключевых слов и фраз, которые могут указывать на наличие вопроса в тексте. Например, регулярное выражение "как [а-яА-ЯёЁ]+" может использоваться для поиска предложений, начинающихся со слова "как", что часто является признаком вопроса.
Кроме того, можно использовать правила на основе грамматики для анализа структуры предложения и выявления в нем вопросительной интонации. Например, в английском языке вопросительные предложения обычно начинаются с вспомогательного глагола или модального глагола, например, "Do you like pizza?" или "Can you help me?". Такие правила могут быть формализованы с помощью контекстно-свободных грамматик или других формализмов для представления грамматической структуры предложения.
Такой подход может давать более точные результаты, но требует большого количества правил и знаний о языке, а также может иметь проблемы с обработкой нетипичных случаев и с различными языковыми особенностями.
               
Решения на базе машинного обучения
1. Наивный Байесовский классификатор (Naive Bayes Classifier) [14] - это метод машинного обучения, который используется для классификации текстовых данных. Он основан на теореме Байеса, которая позволяет вычислить вероятность принадлежности документа к конкретному классу. Для распознавания вопросов в тексте можно обучить наивный Байесовский классификатор на корпусе текстовых данных, содержащих вопросы и не вопросы, и затем использовать его для классификации новых текстовых данных.
2. Методы машинного обучения на основе алгоритмов кластеризации - это методы, которые позволяют группировать схожие текстовые данные в кластеры. Для распознавания вопросов в тексте можно использовать алгоритм кластеризации, который позволит группировать текстовые данные, содержащие вопросы, в отдельный кластер [14].
3. Рекуррентные нейронные сети (RNN) [15] - это методы машинного обучения, которые обрабатывают последовательность данных. Они обычно используются для обработки текстовых данных. Для распознавания вопросов в тексте можно обучить RNN на корпусе текстовых данных, содержащих вопросы и не вопросы, и затем использовать его для классификации новых текстовых данных.
4. Алгоритмы обработки естественного языка (Natural Language Processing, NLP) [14] - это методы обработки текстовых данных, которые позволяют выделять смысловые единицы из текста. Для распознавания вопросов в тексте можно использовать NLP-алгоритмы, которые позволят выделить ключевые слова и фразы, характерные для вопросов, и использовать их для классификации текстовых данных.

               3.5.2 Выбор и проектирование решения для определения вопросов в тексте
Все перечисленные решения на основе машинного обучения требуют наличия специально подобранного датасета (датасетов) в для обучения и подгонки конкретного решения. 
В условиях выполнения выпускной квалификационной работы такой датасет отсутствовал, поэтому было принято решения использовать регулярные выражения. Для этого было просмотрено большое количество очных и дистанционных защит бакалавров, подключен собственный опыт защит лабораторных и курсовых работ, а также опыт защиты выпускной квалификационной работы бакалавра. В результате был составлен список ключевых фраз, которые часто используются преподавателями и комиссией для формирования вопросов. Данный список был преобразован в регулярные выражения. Полученный список регулярный выражений: